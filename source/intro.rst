**Introduction to The Xi Project**
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The **Xi** project is a trial in the application
of "Deep Learning" to interactive proof.

To give maximum scope for adaptation of interative
proof to the exploitation of deep learning the project
uses a completely new ITP (Interactive Theorem Prover) system, which implements
a new language and logic in novel ways.
The name Xi is used for the project, the language and logic, and for the
interactive theorem prover.

My own background is primarily with the Cambridge HOL system and with
ProofPower, so often in describing Xi I will use comparisons with HOL or
ProofPower.

The main aim is to try out the application of deep learning to ITP, so the
other new things I am thinking of doing with this project are secondary,
and any of them that seems to be getting in the way of the deep learning
I may decide to drop.
There's no particular reason why any of them *should* get in the way, but
any of them might prove to be more difficult than I imagine and in that
way might get in the way of my primary purposes, in which case it may get dropped.

I'm going to list here the aspects of the project, as I now envisage it,
which I think of greatest interest.

-  The abstract language and logic Xi

   This is an un-typed illative lambda calculus
   
-  A distributed theory datatabase

   Work with the Xi ITP starts in an existing "context" which is defined by a file

